{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Machine Learning Zoo - Comprehensive Guide\n\nA hands-on walkthrough of every major subsystem in the Machine Learning Zoo: model composition, training strategies, reinforcement learning, neuro-symbolic reasoning, fairness, explainability, and more.\n\n**Table of Contents**\n\n1. [Setup & Imports](#1)\n2. [Device Management](#2)\n3. [The Registry System](#3)\n4. [Backbones (Feature Extractors)](#4)\n5. [Heads (Task-Specific Layers)](#5)\n6. [Model Composition with `build_model`](#6)\n7. [Evaluation Toolkit](#7)\n8. [Neuro-Symbolic Methods](#8)\n9. [Reinforcement Learning - Single Agent](#9)\n10. [Multi-Agent RL Environments](#10)\n11. [Multi-Agent Policy & MAPPO Training](#11)\n12. [Domain Adaptation](#12)\n13. [Continual Learning (EWC)](#13)\n14. [Federated Learning](#14)\n15. [Fairness Auditing](#15)\n16. [Explainability](#16)\n17. [Sidecar & IPC Architecture](#17)\n18. [Configuration with Hydra / OmegaConf](#18)\n19. [Project Architecture](#19)\n20. [Next Steps & Resources](#20)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"1\"></a>\n## 1. Setup & Imports\n\nAdd the project root to `sys.path` so we can import `src` modules directly from the notebook."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys, pathlib\n\n# Ensure the project root is on the import path\nROOT = pathlib.Path.cwd().parent\nif str(ROOT) not in sys.path:\n    sys.path.insert(0, str(ROOT))\n\nimport torch\nimport numpy as np\n\nprint(f\"PyTorch {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nprint(f\"MPS available:  {hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"2\"></a>\n## 2. Device Management\n\n`DeviceManager` probes the system for CPUs, NVIDIA GPUs, and Apple MPS, then recommends the best device for a given workload."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from src.device.manager import DeviceManager\n\ndm = DeviceManager()\nsystem_info = dm.probe()\n\nprint(f\"Platform:  {system_info.platform}\")\nprint(f\"CPU:       {system_info.cpu.brand} ({system_info.cpu.cores_physical}P / {system_info.cpu.cores_logical}L cores)\")\nprint(f\"RAM:       {system_info.ram_total_mb:,} MB total, {system_info.ram_available_mb:,} MB free\")\nprint(f\"GPUs:      {len(system_info.gpus)}\")\nfor gpu in system_info.gpus:\n    print(f\"  [{gpu.index}] {gpu.name} ({gpu.vendor}) - {gpu.vram_total_mb:,} MB VRAM\")\n\nrecommended = dm.best_device_for(\"training\", model_size_mb=500)\nprint(f\"\\nRecommended device for training (500 MB model): {recommended}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"3\"></a>\n## 3. The Registry System\n\nEvery backbone and head is registered at import time via decorators (`@register_backbone`, `@register_head`). You can list available components and look them up by name."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from src.models.backbones import BACKBONE_REGISTRY\nfrom src.models.heads import HEAD_REGISTRY\n\nprint(\"Available backbones:\")\nfor name, cls in BACKBONE_REGISTRY.items():\n    print(f\"  {name:20s} -> {cls.__name__}\")\n\nprint(\"\\nAvailable heads:\")\nfor name, cls in HEAD_REGISTRY.items():\n    print(f\"  {name:20s} -> {cls.__name__}\")"
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"4\"></a>\n## 4. Backbones (Feature Extractors)\n\nBackbones are task-agnostic networks that turn raw inputs into fixed-size feature vectors. The Zoo ships with Transformer, LSTM, Mamba, Conv, HuggingFace, Vision, and MultiModal backbones.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from src.models.backbones import (\n    TransformerBackbone, TransformerBackboneConfig,\n    LSTMBackbone, LSTMBackboneConfig,\n)\n\n# --- Transformer backbone ---\ntf_cfg = TransformerBackboneConfig(\n    input_dim=16, hidden_dim=64, num_layers=2, num_heads=4, ff_dim=128, dropout=0.1,\n)\ntf_backbone = TransformerBackbone(tf_cfg)\n\nx_seq = torch.randn(2, 10, 16)                     # (batch=2, seq=10, features=16)\ntf_out = tf_backbone(x_seq)\nprint(f\"Transformer  input:  {tuple(x_seq.shape)}\")\nprint(f\"Transformer  output: {tuple(tf_out.shape)}  (output_dim={tf_backbone.output_dim})\")\n\n# --- LSTM backbone ---\nlstm_cfg = LSTMBackboneConfig(\n    input_dim=16, hidden_dim=64, num_layers=2, bidirectional=True, dropout=0.1,\n)\nlstm_backbone = LSTMBackbone(lstm_cfg)\n\nlstm_out = lstm_backbone(x_seq)\nprint(f\"\\nLSTM  input:  {tuple(x_seq.shape)}\")\nprint(f\"LSTM  output: {tuple(lstm_out.shape)}  (output_dim={lstm_backbone.output_dim})\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"5\"></a>\n## 5. Heads (Task-Specific Layers)\n\nHeads attach to backbone features and produce task-specific outputs: class logits, regression values, RL policies, etc.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from src.models.heads import (\n    ClassificationHead, ClassificationHeadConfig,\n    RegressionHead, RegressionHeadConfig,\n    RLPolicyHead, RLPolicyHeadConfig,\n)\n\nfeatures = torch.randn(2, 64)  # pretend backbone output (batch=2, dim=64)\n\n# --- Classification ---\ncls_head = ClassificationHead(ClassificationHeadConfig(\n    input_dim=64, num_classes=5, hidden_dims=(32,), pool_type=\"mean\",\n))\nlogits = cls_head(features)\nprint(f\"Classification logits: {tuple(logits.shape)}\")  # (2, 5)\n\n# --- Regression ---\nreg_head = RegressionHead(RegressionHeadConfig(\n    input_dim=64, output_dim=1, output_activation=\"none\",\n))\npreds = reg_head(features)\nprint(f\"Regression output:     {tuple(preds.shape)}\")  # (2, 1)\n\n# --- RL Policy (Actor-Critic) ---\nrl_head = RLPolicyHead(RLPolicyHeadConfig(\n    input_dim=64, action_dim=3, continuous=False, hidden_dims=(32,),\n))\npolicy_out = rl_head(features)\nprint(f\"\\nRL Policy output fields: {policy_out._fields}\")\nprint(f\"  action_logits: {tuple(policy_out.action_logits.shape)}\")\nprint(f\"  value:         {tuple(policy_out.value.shape)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"6\"></a>\n## 6. Model Composition with `build_model`\n\n`build_model` is the primary factory: pick a backbone name, a head name, pass config dicts, and get a ready-to-train `ComposedModel`.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from src.models.composed import build_model\n\n# Build a Transformer + Classification model in one call\nmodel = build_model(\n    backbone_name=\"transformer\",\n    head_name=\"classification\",\n    backbone_config={\"input_dim\": 16, \"hidden_dim\": 64, \"num_layers\": 2, \"num_heads\": 4},\n    head_config={\"num_classes\": 5},\n)\n\nx = torch.randn(4, 10, 16)     # (batch=4, seq=10, features=16)\nout = model(x)\nprint(f\"ComposedModel output: {tuple(out.shape)}\")  # (4, 5)\n\n# Parameter count\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable   = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"Parameters: {total_params:,} total, {trainable:,} trainable\")\n\n# Freeze the backbone for transfer learning\nmodel.freeze_backbone()\ntrainable_after = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"After freeze_backbone: {trainable_after:,} trainable (head only)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"7\"></a>\n## 7. Evaluation Toolkit\n\n`Evaluator` provides unified metrics for classification (accuracy, macro-F1), regression (MSE, MAE), and generation (perplexity).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from src.training.evaluation import Evaluator\n\n# Classification metrics\ny_true = torch.tensor([0, 1, 2, 1, 0, 2, 1, 0])\ny_pred = torch.tensor([0, 1, 2, 1, 0, 1, 1, 0])  # one mistake\ncls_metrics = Evaluator.evaluate(\"classification\", y_true, y_pred)\nprint(\"Classification:\", cls_metrics)\n\n# Regression metrics\ny_true_r = torch.tensor([1.0, 2.0, 3.0, 4.0])\ny_pred_r = torch.tensor([1.1, 2.2, 2.8, 4.3])\nreg_metrics = Evaluator.evaluate(\"regression\", y_true_r, y_pred_r)\nprint(\"Regression:    \", reg_metrics)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"8\"></a>\n## 8. Neuro-Symbolic Methods\n\n`NeuroSymbolicNetwork` fuses a neural pathway with symbolic reasoning (learnable rules + a differentiable logic program executor). Three integration modes are supported: **gated**, **residual**, and **attention**.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from src.models.neuro_symbolic import NeuroSymbolicConfig, NeuroSymbolicNetwork\n\nns_cfg = NeuroSymbolicConfig(\n    input_dim=32, hidden_dim=64, output_dim=5,\n    num_rules=16, rule_dim=32, num_predicates=8,\n    integration_mode=\"gated\", symbolic_depth=2,\n)\nns_model = NeuroSymbolicNetwork(ns_cfg)\n\nx = torch.randn(4, 32)  # (batch=4, input_dim=32)\nns_out = ns_model(x)\n\nprint(\"NeuroSymbolicOutput fields:\", ns_out._fields)\nprint(f\"  prediction:     {tuple(ns_out.prediction.shape)}\")\nprint(f\"  neural_output:  {tuple(ns_out.neural_output.shape)}\")\nprint(f\"  symbolic_output:{tuple(ns_out.symbolic_output.shape)}\")\nprint(f\"  rule_attention: {tuple(ns_out.rule_attention.shape)}\")\nprint(f\"  confidence:     {tuple(ns_out.confidence.shape)}\")\n\n# Symbolic constraint loss: classes 0 and 1 are mutually exclusive,\n# class 2 implies class 3\nconstraints = [(0, 1, \"mutex\"), (2, 3, \"implies\")]\npenalty = ns_model.symbolic_loss(ns_out.prediction, constraints)\nprint(f\"\\nSymbolic constraint penalty: {penalty.item():.4f}\")\n\n# Inspect learned rule importance\nrules = ns_model.get_rule_importance()\nprint(f\"Rule embeddings shape: {tuple(rules.shape)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"9\"></a>\n## 9. Reinforcement Learning - Single Agent\n\nThe `TradingEnv` is a Gymnasium-compatible environment where an RL agent trades a price series. We pair it with an `RLPolicyHead` and run a short episode.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from src.envs import TradingEnv\n\nenv = TradingEnv(initial_capital=10_000.0, lookback=10, max_steps=50)\nobs, info = env.reset(seed=42)\nprint(f\"Observation shape: {obs.shape}\")   # (lookback, 6)\nprint(f\"Action space:      {env.action_space}\")  # Discrete(3)\n\n# Run a short episode with the RL policy head\nflat_dim = obs.shape[0] * obs.shape[1]   # flatten obs for the head\nrl_head = RLPolicyHead(RLPolicyHeadConfig(\n    input_dim=flat_dim, action_dim=3, continuous=False, hidden_dims=(64,),\n))\n\ntotal_reward = 0.0\nfor step in range(20):\n    obs_t = torch.tensor(obs.flatten(), dtype=torch.float32).unsqueeze(0)\n    action, log_prob, value = rl_head.get_action(obs_t)\n    obs, reward, terminated, truncated, info = env.step(int(action.item()))\n    total_reward += reward\n    if terminated or truncated:\n        break\n\nprint(f\"\\nEpisode finished after {step+1} steps\")\nprint(f\"Total reward: {total_reward:.4f}\")\nprint(f\"Final portfolio: ${info['portfolio_value']:.2f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"10\"></a>\n## 10. Multi-Agent RL Environments\n\nTwo built-in multi-agent environments demonstrate cooperative and competitive scenarios:\n- **CooperativeGatheringEnv** -- agents collect resources on a grid with shared rewards\n- **CompetitiveArenaEnv** -- agents compete for territory control",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from src.envs.multi_agent import (\n    MultiAgentEnvConfig, CooperativeGatheringEnv, CompetitiveArenaEnv,\n)\n\n# --- Cooperative gathering ---\ncoop_cfg = MultiAgentEnvConfig(num_agents=3, grid_size=8, max_steps=50, reward_type=\"shared\")\ncoop_env = CooperativeGatheringEnv(coop_cfg, num_resources=6)\n\nobs, _ = coop_env.reset(seed=0)\nprint(f\"Agents: {coop_env.agents}\")\nprint(f\"Obs shape per agent: {obs['agent_0'].shape}\")\n\n# Random rollout\nfor t in range(20):\n    actions = {a: coop_env._agent_act_space.sample() for a in coop_env.agents}\n    obs, rewards, done, truncated, info = coop_env.step(actions)\n    if done or truncated:\n        break\n\nprint(f\"After {t+1} steps -> collected {info['collected']}/{info['total_resources']} resources\")\nprint(f\"Rewards: { {a: f'{r:.2f}' for a, r in rewards.items()} }\")\n\n# --- Competitive arena ---\ncomp_cfg = MultiAgentEnvConfig(num_agents=3, grid_size=6, max_steps=30, reward_type=\"individual\")\ncomp_env = CompetitiveArenaEnv(comp_cfg)\n\nobs, _ = comp_env.reset(seed=0)\nfor t in range(15):\n    actions = {a: comp_env._agent_act_space.sample() for a in comp_env.agents}\n    obs, rewards, done, truncated, info = comp_env.step(actions)\n\nprint(f\"\\nCompetitive arena after {t+1} steps:\")\nprint(f\"  Territory: {info['territory']}\")\nprint(f\"  Unclaimed: {info['unclaimed']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"11\"></a>\n## 11. Multi-Agent Policy & MAPPO Training\n\n`MultiAgentPolicyHead` implements centralized-training-decentralized-execution (CTDE): agents share a centralized value function during training but act independently at inference time. `MAPPOTrainer` orchestrates the full training loop.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from src.models.heads import MultiAgentPolicyHead, MultiAgentPolicyHeadConfig\nfrom src.training.multi_agent_rl import MARLConfig, MAPPOTrainer\n\nnum_agents = 3\nobs_dim = obs[\"agent_0\"].shape[0]  # from the competitive env above\n\n# Build multi-agent policy\nma_head = MultiAgentPolicyHead(MultiAgentPolicyHeadConfig(\n    input_dim=obs_dim,\n    action_dim=5,          # 5 movement actions\n    num_agents=num_agents,\n    continuous=False,\n    shared_parameters=True,\n    hidden_dims=(64,),\n))\n\n# Quick forward pass\ndummy_features = torch.randn(num_agents, 2, obs_dim)  # (agents, batch=2, obs_dim)\nma_out = ma_head(dummy_features)\nprint(f\"action_logits: {tuple(ma_out.action_logits.shape)}\")  # (agents, batch, 5)\nprint(f\"values:        {tuple(ma_out.values.shape)}\")          # (agents, batch)\n\n# Set up MAPPO trainer\nmarl_cfg = MARLConfig(\n    num_agents=num_agents,\n    learning_rate=3e-4,\n    gamma=0.99,\n    rollout_length=32,\n    num_epochs=2,\n    num_minibatches=2,\n)\ntrainer = MAPPOTrainer(policy=ma_head, config=marl_cfg)\n\n# Collect one rollout and update\ncomp_env2 = CompetitiveArenaEnv(comp_cfg)\nobs_init, _ = comp_env2.reset(seed=1)\nrollout_info = trainer.collect_rollout(comp_env2, obs_init)\nmetrics = trainer.update()\n\nprint(f\"\\nMAPPO update metrics:\")\nfor k, v in metrics.items():\n    print(f\"  {k}: {v:.4f}\")\nprint(f\"Total env steps: {rollout_info['total_steps']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"12\"></a>\n## 12. Domain Adaptation\n\nWhen training and deployment data come from different distributions, domain adaptation helps bridge the gap. The Zoo provides:\n\n| Component | Purpose |\n|---|---|\n| `GradientReversalLayer` | Reverses gradients so the feature extractor learns domain-invariant representations |\n| `MMDLoss` | Maximum Mean Discrepancy -- measures distribution distance in an RKHS |\n| `DomainDiscriminator` | Binary classifier distinguishing source vs. target domains |",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from src.training.domain_adaptation import GradientReversalLayer, MMDLoss, DomainDiscriminator\n\n# Synthetic source and target distributions\nsource_features = torch.randn(32, 64)          # source domain\ntarget_features = torch.randn(32, 64) + 0.5    # shifted target domain\n\n# MMD loss measures distribution distance\nmmd = MMDLoss(kernel_type=\"rbf\")\nmmd_same   = mmd(source_features, source_features)\nmmd_cross  = mmd(source_features, target_features)\nprint(f\"MMD (source vs source): {mmd_same.item():.4f}  (should be ~0)\")\nprint(f\"MMD (source vs target): {mmd_cross.item():.4f}  (should be > 0)\")\n\n# Gradient Reversal Layer -- data passes through unchanged, gradients flip\ngrl = GradientReversalLayer(alpha=1.0)\nx = torch.randn(4, 64, requires_grad=True)\ny = grl(x)\nprint(f\"\\nGRL forward:  input == output? {torch.allclose(x, y)}\")\n\n# Domain discriminator\ndisc = DomainDiscriminator(input_dim=64, hidden_dim=32)\ndomain_logits = disc(source_features[:4])\nprint(f\"Discriminator output: {tuple(domain_logits.shape)}\")  # (4, 2)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"13\"></a>\n## 13. Continual Learning (EWC)\n\nElastic Weight Consolidation prevents catastrophic forgetting when training on a sequence of tasks. It penalizes changes to parameters that were important for earlier tasks, as measured by the Fisher Information Matrix. A `ReplayBuffer` stores samples from previous tasks for experience rehearsal.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from src.training.continual import EWCCallback, ReplayBuffer\n\n# EWC callback -- would be used with PyTorch Lightning Trainer\newc = EWCCallback(ewc_lambda=0.4)\nprint(f\"EWC lambda: {ewc.ewc_lambda}\")\nprint(f\"Stored tasks: {len(ewc.fisher_matrices)}\")\n\n# Replay buffer for experience rehearsal\nbuf = ReplayBuffer(capacity=100)\nbuf.add_samples(list(range(50)))\nbuf.add_samples(list(range(50, 120)))  # exceeds capacity -> keeps last 100\nprint(f\"\\nReplay buffer size: {len(buf.buffer)} (capacity={buf.capacity})\")\nprint(f\"Sample 5 items:     {buf.sample(5)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"14\"></a>\n## 14. Federated Learning\n\n`FederatedAggregator` and `FederatedClient` implement FedAvg for privacy-preserving distributed training. Each client trains locally; the server aggregates updates weighted by dataset size.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from src.training.federated import FederatedAggregator, FederatedClient\n\n# Create a small global model\nglobal_model = torch.nn.Linear(8, 2)\n\n# Server\nserver = FederatedAggregator(global_model)\n\n# Simulate 3 clients with local training\nclients = [FederatedClient(torch.nn.Linear(8, 2), client_id=f\"hospital_{i}\") for i in range(3)]\ndataset_sizes = [500, 300, 200]\n\nfor client, n_samples in zip(clients, dataset_sizes):\n    # Pull latest global weights\n    client.pull_global_weights(global_model.state_dict())\n    # Simulate local training by adding noise to weights\n    with torch.no_grad():\n        for p in client.model.parameters():\n            p.add_(torch.randn_like(p) * 0.1)\n    # Send update back to server\n    server.register_client_update(client.get_local_update(), n_samples)\n\n# Aggregate using FedAvg\nnew_global = server.aggregate()\nprint(\"FedAvg aggregation complete.\")\nprint(f\"Global weight sample: {list(new_global.values())[0][0, :4].tolist()}\")\nprint(f\"Pending client updates: {len(server.client_weights)} (cleared after aggregation)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"15\"></a>\n## 15. Fairness Auditing\n\n`FairnessAuditor` measures bias across sensitive attributes using three standard metrics:\n\n| Metric | Ideal Value | Interpretation |\n|---|---|---|\n| Demographic Parity Difference | 0.0 | Max gap in positive-prediction rate between groups |\n| Disparate Impact Ratio | 1.0 (> 0.8 is the \"80 % rule\") | Ratio of selection rates between least/most favored group |\n| Equalized Odds Difference | 0.0 | Max gap in TPR or FPR between groups |",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from src.training.fairness import FairnessAuditor\n\n# Synthetic predictions and sensitive attributes\ntorch.manual_seed(42)\ny_true     = torch.randint(0, 2, (200,))\ny_pred     = torch.randint(0, 2, (200,))\n# Two demographic groups: 0 and 1\nsensitive   = torch.cat([torch.zeros(100, dtype=torch.long), torch.ones(100, dtype=torch.long)])\n\nauditor = FairnessAuditor()\nreport = auditor.audit(y_true, y_pred, sensitive)\n\nprint(\"Fairness Audit Report:\")\nfor metric, value in report.items():\n    print(f\"  {metric:30s} = {value:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"16\"></a>\n## 16. Explainability\n\n`ExplainabilityModule` provides Integrated Gradients for input attribution. Given a model and an input, it computes how much each input feature contributed to a target class prediction.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from src.training.explainability import ExplainabilityModule\n\n# Small classifier for demonstration\nsmall_model = torch.nn.Sequential(\n    torch.nn.Linear(8, 32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32, 3),  # 3 classes\n)\n\nsample_input = torch.randn(1, 8)\ntarget_class = 1\n\nattributions = ExplainabilityModule.integrated_gradients(\n    model=small_model,\n    inputs=sample_input,\n    target_idx=target_class,\n    steps=30,\n)\n\nprint(f\"Input shape:       {tuple(sample_input.shape)}\")\nprint(f\"Attribution shape:  {tuple(attributions.shape)}\")\nprint(f\"Top contributing features (by abs attribution):\")\nabs_attr = attributions.abs().squeeze()\ntop_k = torch.topk(abs_attr, k=3)\nfor idx, val in zip(top_k.indices.tolist(), top_k.values.tolist()):\n    print(f\"  feature {idx}: {val:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"17\"></a>\n## 17. Sidecar & IPC Architecture\n\nThe ML Zoo can run as a **Python sidecar** to a Rust/React host application. Communication happens over **NDJSON** (newline-delimited JSON) on stdin/stdout.\n\n```\n┌─────────────┐    stdin (NDJSON)    ┌──────────────────────┐\n│  Rust / TS   │ ──────────────────▶ │  NdjsonTransport     │\n│  Host App    │                     │  ↓                   │\n│              │ ◀────────────────── │  MlRequestHandler    │\n└─────────────┘   stdout (NDJSON)    │  ├─ inference.*      │\n                                     │  ├─ model.*          │\n                                     │  ├─ training.*       │\n                                     │  ├─ device.*         │\n                                     │  └─ voice.*          │\n                                     └──────────────────────┘\n```\n\n**Supported RPC methods** (dispatched by `MlRequestHandler`):\n\n| Namespace | Methods |\n|-----------|---------|\n| `health` | `ping` |\n| `inference` | `complete`, `complete_stream`, `embed`, `plan`, `load_model` |\n| `model` | `list`, `load`, `unload`, `download`, `migrate` |\n| `training` | `start`, `stop`, `status`, `list`, `deploy`, `predict` |\n| `device` | `info`, `refresh` |\n| `voice` | `synthesize`, `transcribe` |\n| `personality` | `hatch_chat` |\n\nThe entry point is `src/ml_sidecar_main.py`, which wires `NdjsonTransport` &#8594; `MlRequestHandler` &#8594; `InferenceEngine` / `ModelRegistry` / `DeviceManager`.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"18\"></a>\n## 18. Configuration with Hydra / OmegaConf\n\nThe Zoo uses Hydra-style YAML configs organised into groups under `configs/`. At runtime, `OmegaConf` merges defaults with overrides and `deep_sanitize` converts them to plain Python dicts for PyTorch Lightning.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from omegaconf import OmegaConf\nfrom src.utils.config import deep_sanitize\n\n# Configs are plain YAML dicts -- here we create one inline\ncfg = OmegaConf.create({\n    \"model\": {\n        \"backbone\": \"transformer\",\n        \"head\": \"classification\",\n        \"backbone_config\": {\"hidden_dim\": 128, \"num_layers\": 4, \"num_heads\": 4},\n        \"head_config\": {\"num_classes\": 10},\n    },\n    \"training\": {\n        \"learning_rate\": 3e-4,\n        \"max_epochs\": 20,\n        \"batch_size\": 64,\n    },\n    \"seed\": 42,\n})\n\n# deep_sanitize converts OmegaConf containers to plain dicts / lists\nplain = deep_sanitize(cfg)\nprint(\"Sanitised config (plain Python dict):\")\nfor section, values in plain.items():\n    print(f\"  {section}: {values}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"19\"></a>\n## 19. Project Architecture\n\n```\nMachine-Learning-Zoo/\n├── src/\n│   ├── main.py                  # CLI entry point (build & demo models)\n│   ├── ml_sidecar_main.py       # Sidecar server (NDJSON IPC)\n│   │\n│   ├── models/                  # All model definitions\n│   │   ├── backbones/           #   Feature extractors (Transformer, LSTM, Mamba, Conv, HF, Vision, MultiModal)\n│   │   ├── heads/               #   Task heads (Classification, Regression, RLPolicy, Sequence, MultiAgentPolicy)\n│   │   ├── composed.py          #   build_model() factory\n│   │   ├── registry.py          #   get_model() + MODEL_REGISTRY\n│   │   ├── neuro_symbolic.py    #   Hybrid neural-symbolic architectures\n│   │   ├── autoencoders/        #   VAE, SAE, Denoising AE, Stacked AE\n│   │   ├── probabilistic/       #   RBM, DBN, Flows, Diffusion, GAN, Hopfield, Markov\n│   │   ├── convolutional/       #   CNN, ResNet, Capsule, DeConv\n│   │   ├── recurrent/           #   LSTM, GRU, xLSTM, Mamba, Echo State, Liquid State\n│   │   ├── attention/           #   Transformer variants\n│   │   ├── spiking/             #   SNN with LIF cells\n│   │   ├── graphs/              #   GNN layers\n│   │   ├── memory/              #   NTM, DNC\n│   │   ├── competitive/         #   SOM, LVQ\n│   │   ├── general/             #   MLP, RBF, ELM, PINN, NODE\n│   │   ├── ensemble.py          #   Ensemble strategies\n│   │   ├── mac/                 #   Classical ML (linear, trees, SVM, kNN, Bayes, ensemble)\n│   │   └── helper/              #   Clustering, dim-reduction, association rules\n│   │\n│   ├── training/                # Training infrastructure\n│   │   ├── trainer.py           #   ProgressCallback for Lightning\n│   │   ├── lightning_module.py  #   PiLightningModule (LoRA, QLoRA, distillation)\n│   │   ├── data_module.py       #   PiDataModule\n│   │   ├── evaluation.py        #   Unified metrics\n│   │   ├── explainability.py    #   Integrated Gradients, attention maps\n│   │   ├── fairness.py          #   Bias auditing\n│   │   ├── domain_adaptation.py #   GRL, MMD, DANN\n│   │   ├── continual.py         #   EWC, replay buffer\n│   │   ├── federated.py         #   FedAvg client / server\n│   │   ├── multi_agent_rl.py    #   MAPPO trainer\n│   │   └── automl.py            #   Optuna-based HPO\n│   │\n│   ├── inference/               # Multi-provider inference engine\n│   │   ├── engine.py            #   InferenceEngine (local, Anthropic, Google, Deepseek)\n│   │   ├── completion.py        #   Token generation\n│   │   └── embeddings.py        #   Sentence embeddings\n│   │\n│   ├── envs/                    # Gymnasium environments\n│   │   ├── base.py              #   EnvironmentProtocol, TradingEnvBase\n│   │   ├── envs.py              #   TradingEnv, ClobEnv, PolymarketEnv\n│   │   └── multi_agent.py       #   CooperativeGatheringEnv, CompetitiveArenaEnv\n│   │\n│   ├── pipeline/                # Training pipelines\n│   │   ├── core/                #   Supervised, Unsupervised, SSL, GAN, Diffusion, RL (PPO / SAC)\n│   │   ├── hpo/                 #   DEHB, Ray Tune, Optuna\n│   │   ├── meta/                #   MAML, regime detection\n│   │   ├── online_learning/     #   Online trainer, drift detection\n│   │   └── active_learning/     #   Uncertainty & variance-reduction sampling\n│   │\n│   ├── features/                # Feature engineering\n│   │   ├── pipeline.py          #   FeaturePipeline (scaling, selection, regime detection)\n│   │   ├── normalization.py     #   OnlineNormalizer (Welford's algorithm)\n│   │   └── regime.py            #   MarketRegimeDetector (HMM)\n│   │\n│   ├── device/                  # Hardware management\n│   │   └── manager.py           #   DeviceManager (CPU, CUDA, MPS probing)\n│   │\n│   ├── ipc/                     # Inter-process communication\n│   │   └── ndjson_transport.py  #   Async NDJSON over stdin/stdout\n│   │\n│   ├── configs/                 # Hydra / OmegaConf configuration\n│   │\n│   └── utils/                   # Utilities\n│       ├── registry.py          #   Generic Registry[T], global registries\n│       ├── config.py            #   deep_sanitize, sanitize_and_inject\n│       ├── profiling/           #   Benchmarking, GPU optimisation\n│       ├── io/                  #   MLflow, cloud storage, model versioning\n│       ├── security/            #   Secrets management\n│       └── export/              #   ONNX export\n│\n├── configs/                     # YAML config files\n├── tests/                       # Pytest suite (unit, integration, property)\n├── notebooks/                   # This notebook\n├── examples/                    # Standalone example scripts\n└── benchmark/                   # Performance benchmarks\n```",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"20\"></a>\n## 20. Next Steps & Resources\n\n**Where to go from here:**\n\n- **ROADMAP.md** -- Planned features across 9 phases (foundation through community growth).\n- **examples/** -- Standalone scripts demonstrating dashboards, training workflows, and inference.\n- **tests/** -- The test suite doubles as executable documentation. Run with `pytest tests/`.\n- **configs/** -- Browse the YAML config groups (`model/`, `algorithm/`, `env/`, `data/`) for ready-to-use presets.\n- **CLI** -- `python src/main.py --list-presets` to see available model configs; `python src/main.py configs/model/transformer.yaml --demo` to run a quick demo.\n\n**Key design principles:**\n1. **Backbone + Head composition** -- Mix and match any backbone with any head via `build_model()`.\n2. **Registry-driven** -- Every component registers itself; new models integrate by adding a single decorated class.\n3. **PyTorch Lightning** -- Training pipelines use Lightning for distributed training, logging, and callbacks.\n4. **Sidecar-ready** -- The entire library can serve as a subprocess to a host application via NDJSON IPC.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}