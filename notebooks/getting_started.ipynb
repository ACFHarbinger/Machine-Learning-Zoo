{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Machine Learning Zoo - Comprehensive Guide\n\nA hands-on walkthrough of every major subsystem in the Machine Learning Zoo: model composition, training strategies, reinforcement learning, neuro-symbolic reasoning, fairness, explainability, and more.\n\n**Table of Contents**\n\n1. [Setup & Imports](#1)\n2. [Device Management](#2)\n3. [The Registry System](#3)\n4. [Backbones (Feature Extractors)](#4)\n5. [Heads (Task-Specific Layers)](#5)\n6. [Model Composition with `build_model`](#6)\n7. [Evaluation Toolkit](#7)\n8. [Neuro-Symbolic Methods](#8)\n9. [Reinforcement Learning - Single Agent](#9)\n10. [Multi-Agent RL Environments](#10)\n11. [Multi-Agent Policy & MAPPO Training](#11)\n12. [Domain Adaptation](#12)\n13. [Continual Learning (EWC)](#13)\n14. [Federated Learning](#14)\n15. [Fairness Auditing](#15)\n16. [Explainability](#16)\n17. [Sidecar & IPC Architecture](#17)\n18. [Configuration with Hydra / OmegaConf](#18)\n19. [Project Architecture](#19)\n20. [Next Steps & Resources](#20)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"1\"></a>\n## 1. Setup & Imports\n\nAdd the project root to `sys.path` so we can import `src` modules directly from the notebook."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "# Ensure the project root is on the import path\n",
    "ROOT = pathlib.Path.cwd().parent\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"MPS available:  {hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"2\"></a>\n## 2. Device Management\n\n`DeviceManager` probes the system for CPUs, NVIDIA GPUs, and Apple MPS, then recommends the best device for a given workload."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.device.manager import DeviceManager\n",
    "\n",
    "dm = DeviceManager()\n",
    "system_info = dm.probe()\n",
    "\n",
    "print(f\"Platform:  {system_info.platform}\")\n",
    "print(f\"CPU:       {system_info.cpu.brand} ({system_info.cpu.cores_physical}P / {system_info.cpu.cores_logical}L cores)\")\n",
    "print(f\"RAM:       {system_info.ram_total_mb:,} MB total, {system_info.ram_available_mb:,} MB free\")\n",
    "print(f\"GPUs:      {len(system_info.gpus)}\")\n",
    "for gpu in system_info.gpus:\n",
    "    print(f\"  [{gpu.index}] {gpu.name} ({gpu.vendor}) - {gpu.vram_total_mb:,} MB VRAM\")\n",
    "\n",
    "recommended = dm.best_device_for(\"training\", model_size_mb=500)\n",
    "print(f\"\\nRecommended device for training (500 MB model): {recommended}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"3\"></a>\n## 3. The Registry System\n\nEvery backbone and head is registered at import time via decorators (`@register_backbone`, `@register_head`). You can list available components and look them up by name."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.backbones import BACKBONE_REGISTRY\n",
    "from src.models.heads import HEAD_REGISTRY\n",
    "\n",
    "print(\"Available backbones:\")\n",
    "for name, cls in BACKBONE_REGISTRY.items():\n",
    "    print(f\"  {name:20s} -> {cls.__name__}\")\n",
    "\n",
    "print(\"\\nAvailable heads:\")\n",
    "for name, cls in HEAD_REGISTRY.items():\n",
    "    print(f\"  {name:20s} -> {cls.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"4\"></a>\n## 4. Backbones (Feature Extractors)\n\nBackbones are task-agnostic networks that turn raw inputs into fixed-size feature vectors. The Zoo ships with Transformer, LSTM, Mamba, Conv, HuggingFace, Vision, and MultiModal backbones."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.backbones import (\n",
    "    TransformerBackbone, TransformerBackboneConfig,\n",
    "    LSTMBackbone, LSTMBackboneConfig,\n",
    ")\n",
    "\n",
    "# --- Transformer backbone ---\n",
    "tf_cfg = TransformerBackboneConfig(\n",
    "    input_dim=16, hidden_dim=64, num_layers=2, num_heads=4, ff_dim=128, dropout=0.1,\n",
    ")\n",
    "tf_backbone = TransformerBackbone(tf_cfg)\n",
    "\n",
    "x_seq = torch.randn(2, 10, 16)                     # (batch=2, seq=10, features=16)\n",
    "tf_out = tf_backbone(x_seq)\n",
    "print(f\"Transformer  input:  {tuple(x_seq.shape)}\")\n",
    "print(f\"Transformer  output: {tuple(tf_out.shape)}  (output_dim={tf_backbone.output_dim})\")\n",
    "\n",
    "# --- LSTM backbone ---\n",
    "lstm_cfg = LSTMBackboneConfig(\n",
    "    input_dim=16, hidden_dim=64, num_layers=2, bidirectional=True, dropout=0.1,\n",
    ")\n",
    "lstm_backbone = LSTMBackbone(lstm_cfg)\n",
    "\n",
    "lstm_out = lstm_backbone(x_seq)\n",
    "print(f\"\\nLSTM  input:  {tuple(x_seq.shape)}\")\n",
    "print(f\"LSTM  output: {tuple(lstm_out.shape)}  (output_dim={lstm_backbone.output_dim})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"5\"></a>\n## 5. Heads (Task-Specific Layers)\n\nHeads attach to backbone features and produce task-specific outputs: class logits, regression values, RL policies, etc."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.heads import (\n",
    "    ClassificationHead, ClassificationHeadConfig,\n",
    "    RegressionHead, RegressionHeadConfig,\n",
    "    RLPolicyHead, RLPolicyHeadConfig,\n",
    ")\n",
    "\n",
    "features = torch.randn(2, 64)  # pretend backbone output (batch=2, dim=64)\n",
    "\n",
    "# --- Classification ---\n",
    "cls_head = ClassificationHead(ClassificationHeadConfig(\n",
    "    input_dim=64, num_classes=5, hidden_dims=(32,), pool_type=\"mean\",\n",
    "))\n",
    "logits = cls_head(features)\n",
    "print(f\"Classification logits: {tuple(logits.shape)}\")  # (2, 5)\n",
    "\n",
    "# --- Regression ---\n",
    "reg_head = RegressionHead(RegressionHeadConfig(\n",
    "    input_dim=64, output_dim=1, output_activation=\"none\",\n",
    "))\n",
    "preds = reg_head(features)\n",
    "print(f\"Regression output:     {tuple(preds.shape)}\")  # (2, 1)\n",
    "\n",
    "# --- RL Policy (Actor-Critic) ---\n",
    "rl_head = RLPolicyHead(RLPolicyHeadConfig(\n",
    "    input_dim=64, action_dim=3, continuous=False, hidden_dims=(32,),\n",
    "))\n",
    "policy_out = rl_head(features)\n",
    "print(f\"\\nRL Policy output fields: {policy_out._fields}\")\n",
    "print(f\"  action_logits: {tuple(policy_out.action_logits.shape)}\")\n",
    "print(f\"  value:         {tuple(policy_out.value.shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"6\"></a>\n## 6. Model Composition with `build_model`\n\n`build_model` is the primary factory: pick a backbone name, a head name, pass config dicts, and get a ready-to-train `ComposedModel`."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.composed import build_model\n",
    "\n",
    "# Build a Transformer + Classification model in one call\n",
    "model = build_model(\n",
    "    backbone_name=\"transformer\",\n",
    "    head_name=\"classification\",\n",
    "    backbone_config={\"input_dim\": 16, \"hidden_dim\": 64, \"num_layers\": 2, \"num_heads\": 4},\n",
    "    head_config={\"num_classes\": 5},\n",
    ")\n",
    "\n",
    "x = torch.randn(4, 10, 16)     # (batch=4, seq=10, features=16)\n",
    "out = model(x)\n",
    "print(f\"ComposedModel output: {tuple(out.shape)}\")  # (4, 5)\n",
    "\n",
    "# Parameter count\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable   = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Parameters: {total_params:,} total, {trainable:,} trainable\")\n",
    "\n",
    "# Freeze the backbone for transfer learning\n",
    "model.freeze_backbone()\n",
    "trainable_after = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"After freeze_backbone: {trainable_after:,} trainable (head only)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"7\"></a>\n## 7. Evaluation Toolkit\n\n`Evaluator` provides unified metrics for classification (accuracy, macro-F1), regression (MSE, MAE), and generation (perplexity)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipeline.training.evaluation import Evaluator\n",
    "\n",
    "# Classification metrics\n",
    "y_true = torch.tensor([0, 1, 2, 1, 0, 2, 1, 0])\n",
    "y_pred = torch.tensor([0, 1, 2, 1, 0, 1, 1, 0])  # one mistake\n",
    "cls_metrics = Evaluator.evaluate(\"classification\", y_true, y_pred)\n",
    "print(\"Classification:\", cls_metrics)\n",
    "\n",
    "# Regression metrics\n",
    "y_true_r = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "y_pred_r = torch.tensor([1.1, 2.2, 2.8, 4.3])\n",
    "reg_metrics = Evaluator.evaluate(\"regression\", y_true_r, y_pred_r)\n",
    "print(\"Regression:    \", reg_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"8\"></a>\n## 8. Neuro-Symbolic Methods\n\n`NeuroSymbolicNetwork` fuses a neural pathway with symbolic reasoning (learnable rules + a differentiable logic program executor). Three integration modes are supported: **gated**, **residual**, and **attention**."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.neuro_symbolic import NeuroSymbolicConfig, NeuroSymbolicNetwork\n",
    "\n",
    "ns_cfg = NeuroSymbolicConfig(\n",
    "    input_dim=32, hidden_dim=64, output_dim=5,\n",
    "    num_rules=16, rule_dim=32, num_predicates=8,\n",
    "    integration_mode=\"gated\", symbolic_depth=2,\n",
    ")\n",
    "ns_model = NeuroSymbolicNetwork(ns_cfg)\n",
    "\n",
    "x = torch.randn(4, 32)  # (batch=4, input_dim=32)\n",
    "ns_out = ns_model(x)\n",
    "\n",
    "print(\"NeuroSymbolicOutput fields:\", ns_out._fields)\n",
    "print(f\"  prediction:     {tuple(ns_out.prediction.shape)}\")\n",
    "print(f\"  neural_output:  {tuple(ns_out.neural_output.shape)}\")\n",
    "print(f\"  symbolic_output:{tuple(ns_out.symbolic_output.shape)}\")\n",
    "print(f\"  rule_attention: {tuple(ns_out.rule_attention.shape)}\")\n",
    "print(f\"  confidence:     {tuple(ns_out.confidence.shape)}\")\n",
    "\n",
    "# Symbolic constraint loss: classes 0 and 1 are mutually exclusive,\n",
    "# class 2 implies class 3\n",
    "constraints = [(0, 1, \"mutex\"), (2, 3, \"implies\")]\n",
    "penalty = ns_model.symbolic_loss(ns_out.prediction, constraints)\n",
    "print(f\"\\nSymbolic constraint penalty: {penalty.item():.4f}\")\n",
    "\n",
    "# Inspect learned rule importance\n",
    "rules = ns_model.get_rule_importance()\n",
    "print(f\"Rule embeddings shape: {tuple(rules.shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"9\"></a>\n## 9. Reinforcement Learning - Single Agent\n\nThe `TradingEnv` is a Gymnasium-compatible environment where an RL agent trades a price series. We pair it with an `RLPolicyHead` and run a short episode."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.envs import TradingEnv\n",
    "\n",
    "env = TradingEnv(initial_capital=10_000.0, lookback=10, max_steps=50)\n",
    "obs, info = env.reset(seed=42)\n",
    "print(f\"Observation shape: {obs.shape}\")   # (lookback, 6)\n",
    "print(f\"Action space:      {env.action_space}\")  # Discrete(3)\n",
    "\n",
    "# Run a short episode with the RL policy head\n",
    "flat_dim = obs.shape[0] * obs.shape[1]   # flatten obs for the head\n",
    "rl_head = RLPolicyHead(RLPolicyHeadConfig(\n",
    "    input_dim=flat_dim, action_dim=3, continuous=False, hidden_dims=(64,),\n",
    "))\n",
    "\n",
    "total_reward = 0.0\n",
    "for step in range(20):\n",
    "    obs_t = torch.tensor(obs.flatten(), dtype=torch.float32).unsqueeze(0)\n",
    "    action, log_prob, value = rl_head.get_action(obs_t)\n",
    "    obs, reward, terminated, truncated, info = env.step(int(action.item()))\n",
    "    total_reward += reward\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "\n",
    "print(f\"\\nEpisode finished after {step+1} steps\")\n",
    "print(f\"Total reward: {total_reward:.4f}\")\n",
    "print(f\"Final portfolio: ${info['portfolio_value']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"10\"></a>\n## 10. Multi-Agent RL Environments\n\nTwo built-in multi-agent environments demonstrate cooperative and competitive scenarios:\n- **CooperativeGatheringEnv** -- agents collect resources on a grid with shared rewards\n- **CompetitiveArenaEnv** -- agents compete for territory control"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.envs.multi_agent import (\n",
    "    MultiAgentEnvConfig, CooperativeGatheringEnv, CompetitiveArenaEnv,\n",
    ")\n",
    "\n",
    "# --- Cooperative gathering ---\n",
    "coop_cfg = MultiAgentEnvConfig(num_agents=3, grid_size=8, max_steps=50, reward_type=\"shared\")\n",
    "coop_env = CooperativeGatheringEnv(coop_cfg, num_resources=6)\n",
    "\n",
    "obs, _ = coop_env.reset(seed=0)\n",
    "print(f\"Agents: {coop_env.agents}\")\n",
    "print(f\"Obs shape per agent: {obs['agent_0'].shape}\")\n",
    "\n",
    "# Random rollout\n",
    "for t in range(20):\n",
    "    actions = {a: coop_env._agent_act_space.sample() for a in coop_env.agents}\n",
    "    obs, rewards, done, truncated, info = coop_env.step(actions)\n",
    "    if done or truncated:\n",
    "        break\n",
    "\n",
    "print(f\"After {t+1} steps -> collected {info['collected']}/{info['total_resources']} resources\")\n",
    "print(f\"Rewards: { {a: f'{r:.2f}' for a, r in rewards.items()} }\")\n",
    "\n",
    "# --- Competitive arena ---\n",
    "comp_cfg = MultiAgentEnvConfig(num_agents=3, grid_size=6, max_steps=30, reward_type=\"individual\")\n",
    "comp_env = CompetitiveArenaEnv(comp_cfg)\n",
    "\n",
    "obs, _ = comp_env.reset(seed=0)\n",
    "for t in range(15):\n",
    "    actions = {a: comp_env._agent_act_space.sample() for a in comp_env.agents}\n",
    "    obs, rewards, done, truncated, info = comp_env.step(actions)\n",
    "\n",
    "print(f\"\\nCompetitive arena after {t+1} steps:\")\n",
    "print(f\"  Territory: {info['territory']}\")\n",
    "print(f\"  Unclaimed: {info['unclaimed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"11\"></a>\n## 11. Multi-Agent Policy & MAPPO Training\n\n`MultiAgentPolicyHead` implements centralized-training-decentralized-execution (CTDE): agents share a centralized value function during training but act independently at inference time. `MAPPOTrainer` orchestrates the full training loop."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.heads import MultiAgentPolicyHead, MultiAgentPolicyHeadConfig\n",
    "from src.pipeline.training.multi_agent_rl import MARLConfig, MAPPOTrainer\n",
    "\n",
    "num_agents = 3\n",
    "obs_dim = obs[\"agent_0\"].shape[0]  # from the competitive env above\n",
    "\n",
    "# Build multi-agent policy\n",
    "ma_head = MultiAgentPolicyHead(MultiAgentPolicyHeadConfig(\n",
    "    input_dim=obs_dim,\n",
    "    action_dim=5,          # 5 movement actions\n",
    "    num_agents=num_agents,\n",
    "    continuous=False,\n",
    "    shared_parameters=True,\n",
    "    hidden_dims=(64,),\n",
    "))\n",
    "\n",
    "# Quick forward pass\n",
    "dummy_features = torch.randn(num_agents, 2, obs_dim)  # (agents, batch=2, obs_dim)\n",
    "ma_out = ma_head(dummy_features)\n",
    "print(f\"action_logits: {tuple(ma_out.action_logits.shape)}\")  # (agents, batch, 5)\n",
    "print(f\"values:        {tuple(ma_out.values.shape)}\")          # (agents, batch)\n",
    "\n",
    "# Set up MAPPO trainer\n",
    "marl_cfg = MARLConfig(\n",
    "    num_agents=num_agents,\n",
    "    learning_rate=3e-4,\n",
    "    gamma=0.99,\n",
    "    rollout_length=32,\n",
    "    num_epochs=2,\n",
    "    num_minibatches=2,\n",
    ")\n",
    "trainer = MAPPOTrainer(policy=ma_head, config=marl_cfg)\n",
    "\n",
    "# Collect one rollout and update\n",
    "comp_env2 = CompetitiveArenaEnv(comp_cfg)\n",
    "obs_init, _ = comp_env2.reset(seed=1)\n",
    "rollout_info = trainer.collect_rollout(comp_env2, obs_init)\n",
    "metrics = trainer.update()\n",
    "\n",
    "print(\"\\nMAPPO update metrics:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"  {k}: {v:.4f}\")\n",
    "print(f\"Total env steps: {rollout_info['total_steps']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"12\"></a>\n## 12. Domain Adaptation\n\nWhen training and deployment data come from different distributions, domain adaptation helps bridge the gap. The Zoo provides:\n\n| Component | Purpose |\n|---|---|\n| `GradientReversalLayer` | Reverses gradients so the feature extractor learns domain-invariant representations |\n| `MMDLoss` | Maximum Mean Discrepancy -- measures distribution distance in an RKHS |\n| `DomainDiscriminator` | Binary classifier distinguishing source vs. target domains |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipeline.training.domain_adaptation import GradientReversalLayer, MMDLoss, DomainDiscriminator\n",
    "\n",
    "# Synthetic source and target distributions\n",
    "source_features = torch.randn(32, 64)          # source domain\n",
    "target_features = torch.randn(32, 64) + 0.5    # shifted target domain\n",
    "\n",
    "# MMD loss measures distribution distance\n",
    "mmd = MMDLoss(kernel_type=\"rbf\")\n",
    "mmd_same   = mmd(source_features, source_features)\n",
    "mmd_cross  = mmd(source_features, target_features)\n",
    "print(f\"MMD (source vs source): {mmd_same.item():.4f}  (should be ~0)\")\n",
    "print(f\"MMD (source vs target): {mmd_cross.item():.4f}  (should be > 0)\")\n",
    "\n",
    "# Gradient Reversal Layer -- data passes through unchanged, gradients flip\n",
    "grl = GradientReversalLayer(alpha=1.0)\n",
    "x = torch.randn(4, 64, requires_grad=True)\n",
    "y = grl(x)\n",
    "print(f\"\\nGRL forward:  input == output? {torch.allclose(x, y)}\")\n",
    "\n",
    "# Domain discriminator\n",
    "disc = DomainDiscriminator(input_dim=64, hidden_dim=32)\n",
    "domain_logits = disc(source_features[:4])\n",
    "print(f\"Discriminator output: {tuple(domain_logits.shape)}\")  # (4, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"13\"></a>\n## 13. Continual Learning (EWC)\n\nElastic Weight Consolidation prevents catastrophic forgetting when training on a sequence of tasks. It penalizes changes to parameters that were important for earlier tasks, as measured by the Fisher Information Matrix. A `ReplayBuffer` stores samples from previous tasks for experience rehearsal."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipeline.training.continual import EWCCallback, ReplayBuffer\n",
    "\n",
    "# EWC callback -- would be used with PyTorch Lightning Trainer\n",
    "ewc = EWCCallback(ewc_lambda=0.4)\n",
    "print(f\"EWC lambda: {ewc.ewc_lambda}\")\n",
    "print(f\"Stored tasks: {len(ewc.fisher_matrices)}\")\n",
    "\n",
    "# Replay buffer for experience rehearsal\n",
    "buf = ReplayBuffer(capacity=100)\n",
    "buf.add_samples(list(range(50)))\n",
    "buf.add_samples(list(range(50, 120)))  # exceeds capacity -> keeps last 100\n",
    "print(f\"\\nReplay buffer size: {len(buf.buffer)} (capacity={buf.capacity})\")\n",
    "print(f\"Sample 5 items:     {buf.sample(5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"14\"></a>\n## 14. Federated Learning\n\n`FederatedAggregator` and `FederatedClient` implement FedAvg for privacy-preserving distributed training. Each client trains locally; the server aggregates updates weighted by dataset size."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipeline.training.federated import FederatedAggregator, FederatedClient\n",
    "\n",
    "# Create a small global model\n",
    "global_model = torch.nn.Linear(8, 2)\n",
    "\n",
    "# Server\n",
    "server = FederatedAggregator(global_model)\n",
    "\n",
    "# Simulate 3 clients with local training\n",
    "clients = [FederatedClient(torch.nn.Linear(8, 2), client_id=f\"hospital_{i}\") for i in range(3)]\n",
    "dataset_sizes = [500, 300, 200]\n",
    "\n",
    "for client, n_samples in zip(clients, dataset_sizes):\n",
    "    # Pull latest global weights\n",
    "    client.pull_global_weights(global_model.state_dict())\n",
    "    # Simulate local training by adding noise to weights\n",
    "    with torch.no_grad():\n",
    "        for p in client.model.parameters():\n",
    "            p.add_(torch.randn_like(p) * 0.1)\n",
    "    # Send update back to server\n",
    "    server.register_client_update(client.get_local_update(), n_samples)\n",
    "\n",
    "# Aggregate using FedAvg\n",
    "new_global = server.aggregate()\n",
    "print(\"FedAvg aggregation complete.\")\n",
    "print(f\"Global weight sample: {list(new_global.values())[0][0, :4].tolist()}\")\n",
    "print(f\"Pending client updates: {len(server.client_weights)} (cleared after aggregation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"15\"></a>\n## 15. Fairness Auditing\n\n`FairnessAuditor` measures bias across sensitive attributes using three standard metrics:\n\n| Metric | Ideal Value | Interpretation |\n|---|---|---|\n| Demographic Parity Difference | 0.0 | Max gap in positive-prediction rate between groups |\n| Disparate Impact Ratio | 1.0 (> 0.8 is the \"80 % rule\") | Ratio of selection rates between least/most favored group |\n| Equalized Odds Difference | 0.0 | Max gap in TPR or FPR between groups |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipeline.training.fairness import FairnessAuditor\n",
    "\n",
    "# Synthetic predictions and sensitive attributes\n",
    "torch.manual_seed(42)\n",
    "y_true     = torch.randint(0, 2, (200,))\n",
    "y_pred     = torch.randint(0, 2, (200,))\n",
    "# Two demographic groups: 0 and 1\n",
    "sensitive   = torch.cat([torch.zeros(100, dtype=torch.long), torch.ones(100, dtype=torch.long)])\n",
    "\n",
    "auditor = FairnessAuditor()\n",
    "report = auditor.audit(y_true, y_pred, sensitive)\n",
    "\n",
    "print(\"Fairness Audit Report:\")\n",
    "for metric, value in report.items():\n",
    "    print(f\"  {metric:30s} = {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"16\"></a>\n## 16. Explainability\n\n`ExplainabilityModule` provides Integrated Gradients for input attribution. Given a model and an input, it computes how much each input feature contributed to a target class prediction."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipeline.training.explainability import ExplainabilityModule\n",
    "\n",
    "# Small classifier for demonstration\n",
    "small_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(8, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 3),  # 3 classes\n",
    ")\n",
    "\n",
    "sample_input = torch.randn(1, 8)\n",
    "target_class = 1\n",
    "\n",
    "attributions = ExplainabilityModule.integrated_gradients(\n",
    "    model=small_model,\n",
    "    inputs=sample_input,\n",
    "    target_idx=target_class,\n",
    "    steps=30,\n",
    ")\n",
    "\n",
    "print(f\"Input shape:       {tuple(sample_input.shape)}\")\n",
    "print(f\"Attribution shape:  {tuple(attributions.shape)}\")\n",
    "print(\"Top contributing features (by abs attribution):\")\n",
    "abs_attr = attributions.abs().squeeze()\n",
    "top_k = torch.topk(abs_attr, k=3)\n",
    "for idx, val in zip(top_k.indices.tolist(), top_k.values.tolist()):\n",
    "    print(f\"  feature {idx}: {val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"17\"></a>\n## 17. Sidecar & IPC Architecture\n\nThe ML Zoo can run as a **Python sidecar** to a Rust/React host application. Communication happens over **NDJSON** (newline-delimited JSON) on stdin/stdout.\n\n```\n┌─────────────┐    stdin (NDJSON)    ┌──────────────────────┐\n│  Rust / TS   │ ──────────────────▶ │  NdjsonTransport     │\n│  Host App    │                     │  ↓                   │\n│              │ ◀────────────────── │  MlRequestHandler    │\n└─────────────┘   stdout (NDJSON)    │  ├─ inference.*      │\n                                     │  ├─ model.*          │\n                                     │  ├─ training.*       │\n                                     │  ├─ device.*         │\n                                     │  └─ voice.*          │\n                                     └──────────────────────┘\n```\n\n**Supported RPC methods** (dispatched by `MlRequestHandler`):\n\n| Namespace | Methods |\n|-----------|---------|\n| `health` | `ping` |\n| `inference` | `complete`, `complete_stream`, `embed`, `plan`, `load_model` |\n| `model` | `list`, `load`, `unload`, `download`, `migrate` |\n| `training` | `start`, `stop`, `status`, `list`, `deploy`, `predict` |\n| `device` | `info`, `refresh` |\n| `voice` | `synthesize`, `transcribe` |\n| `personality` | `hatch_chat` |\n\nThe entry point is `src/ml_sidecar_main.py`, which wires `NdjsonTransport` &#8594; `MlRequestHandler` &#8594; `InferenceEngine` / `ModelRegistry` / `DeviceManager`."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"18\"></a>\n## 18. Configuration with Hydra / OmegaConf\n\nThe Zoo uses Hydra-style YAML configs organised into groups under `configs/`. At runtime, `OmegaConf` merges defaults with overrides and `deep_sanitize` converts them to plain Python dicts for PyTorch Lightning."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from src.utils.config import deep_sanitize\n",
    "\n",
    "# Configs are plain YAML dicts -- here we create one inline\n",
    "cfg = OmegaConf.create({\n",
    "    \"model\": {\n",
    "        \"backbone\": \"transformer\",\n",
    "        \"head\": \"classification\",\n",
    "        \"backbone_config\": {\"hidden_dim\": 128, \"num_layers\": 4, \"num_heads\": 4},\n",
    "        \"head_config\": {\"num_classes\": 10},\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"learning_rate\": 3e-4,\n",
    "        \"max_epochs\": 20,\n",
    "        \"batch_size\": 64,\n",
    "    },\n",
    "    \"seed\": 42,\n",
    "})\n",
    "\n",
    "# deep_sanitize converts OmegaConf containers to plain dicts / lists\n",
    "plain = deep_sanitize(cfg)\n",
    "print(\"Sanitised config (plain Python dict):\")\n",
    "for section, values in plain.items():\n",
    "    print(f\"  {section}: {values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"19\"></a>\n## 19. Project Architecture\n\n```\nMachine-Learning-Zoo/\n├── src/\n│   ├── main.py                  # CLI entry point (build & demo models)\n│   ├── ml_sidecar_main.py       # Sidecar server (NDJSON IPC)\n│   │\n│   ├── models/                  # All model definitions\n│   │   ├── backbones/           #   Feature extractors (Transformer, LSTM, Mamba, Conv, HF, Vision, MultiModal)\n│   │   ├── heads/               #   Task heads (Classification, Regression, RLPolicy, Sequence, MultiAgentPolicy)\n│   │   ├── composed.py          #   build_model() factory\n│   │   ├── registry.py          #   get_model() + MODEL_REGISTRY\n│   │   ├── neuro_symbolic.py    #   Hybrid neural-symbolic architectures\n│   │   ├── autoencoders/        #   VAE, SAE, Denoising AE, Stacked AE\n│   │   ├── probabilistic/       #   RBM, DBN, Flows, Diffusion, GAN, Hopfield, Markov\n│   │   ├── convolutional/       #   CNN, ResNet, Capsule, DeConv\n│   │   ├── recurrent/           #   LSTM, GRU, xLSTM, Mamba, Echo State, Liquid State\n│   │   ├── attention/           #   Transformer variants\n│   │   ├── spiking/             #   SNN with LIF cells\n│   │   ├── graphs/              #   GNN layers\n│   │   ├── memory/              #   NTM, DNC\n│   │   ├── competitive/         #   SOM, LVQ\n│   │   ├── general/             #   MLP, RBF, ELM, PINN, NODE\n│   │   ├── ensemble.py          #   Ensemble strategies\n│   │   ├── mac/                 #   Classical ML (linear, trees, SVM, kNN, Bayes, ensemble)\n│   │   └── helper/              #   Clustering, dim-reduction, association rules\n│   │\n│   ├── training/                # Training infrastructure\n│   │   ├── trainer.py           #   ProgressCallback for Lightning\n│   │   ├── lightning_module.py  #   PiLightningModule (LoRA, QLoRA, distillation)\n│   │   ├── data_module.py       #   PiDataModule\n│   │   ├── evaluation.py        #   Unified metrics\n│   │   ├── explainability.py    #   Integrated Gradients, attention maps\n│   │   ├── fairness.py          #   Bias auditing\n│   │   ├── domain_adaptation.py #   GRL, MMD, DANN\n│   │   ├── continual.py         #   EWC, replay buffer\n│   │   ├── federated.py         #   FedAvg client / server\n│   │   ├── multi_agent_rl.py    #   MAPPO trainer\n│   │   └── automl.py            #   Optuna-based HPO\n│   │\n│   ├── inference/               # Multi-provider inference engine\n│   │   ├── engine.py            #   InferenceEngine (local, Anthropic, Google, Deepseek)\n│   │   ├── completion.py        #   Token generation\n│   │   └── embeddings.py        #   Sentence embeddings\n│   │\n│   ├── envs/                    # Gymnasium environments\n│   │   ├── base.py              #   EnvironmentProtocol, TradingEnvBase\n│   │   ├── envs.py              #   TradingEnv, ClobEnv, PolymarketEnv\n│   │   └── multi_agent.py       #   CooperativeGatheringEnv, CompetitiveArenaEnv\n│   │\n│   ├── pipeline/                # Training pipelines\n│   │   ├── core/                #   Supervised, Unsupervised, SSL, GAN, Diffusion, RL (PPO / SAC)\n│   │   ├── hpo/                 #   DEHB, Ray Tune, Optuna\n│   │   ├── meta/                #   MAML, regime detection\n│   │   ├── online_learning/     #   Online trainer, drift detection\n│   │   └── active_learning/     #   Uncertainty & variance-reduction sampling\n│   │\n│   ├── features/                # Feature engineering\n│   │   ├── pipeline.py          #   FeaturePipeline (scaling, selection, regime detection)\n│   │   ├── normalization.py     #   OnlineNormalizer (Welford's algorithm)\n│   │   └── regime.py            #   MarketRegimeDetector (HMM)\n│   │\n│   ├── device/                  # Hardware management\n│   │   └── manager.py           #   DeviceManager (CPU, CUDA, MPS probing)\n│   │\n│   ├── ipc/                     # Inter-process communication\n│   │   └── ndjson_transport.py  #   Async NDJSON over stdin/stdout\n│   │\n│   ├── configs/                 # Hydra / OmegaConf configuration\n│   │\n│   └── utils/                   # Utilities\n│       ├── registry.py          #   Generic Registry[T], global registries\n│       ├── config.py            #   deep_sanitize, sanitize_and_inject\n│       ├── profiling/           #   Benchmarking, GPU optimisation\n│       ├── io/                  #   MLflow, cloud storage, model versioning\n│       ├── security/            #   Secrets management\n│       └── export/              #   ONNX export\n│\n├── configs/                     # YAML config files\n├── tests/                       # Pytest suite (unit, integration, property)\n├── notebooks/                   # This notebook\n├── examples/                    # Standalone example scripts\n└── benchmark/                   # Performance benchmarks\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a id=\"20\"></a>\n## 20. Next Steps & Resources\n\n**Where to go from here:**\n\n- **ROADMAP.md** -- Planned features across 9 phases (foundation through community growth).\n- **examples/** -- Standalone scripts demonstrating dashboards, training workflows, and inference.\n- **tests/** -- The test suite doubles as executable documentation. Run with `pytest tests/`.\n- **configs/** -- Browse the YAML config groups (`model/`, `algorithm/`, `env/`, `data/`) for ready-to-use presets.\n- **CLI** -- `python src/main.py --list-presets` to see available model configs; `python src/main.py configs/model/transformer.yaml --demo` to run a quick demo.\n\n**Key design principles:**\n1. **Backbone + Head composition** -- Mix and match any backbone with any head via `build_model()`.\n2. **Registry-driven** -- Every component registers itself; new models integrate by adding a single decorated class.\n3. **PyTorch Lightning** -- Training pipelines use Lightning for distributed training, logging, and callbacks.\n4. **Sidecar-ready** -- The entire library can serve as a subprocess to a host application via NDJSON IPC."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}